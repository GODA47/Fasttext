{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa87c53-902d-4685-a841-bb6d50c2645b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x263173456f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import bcolz\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "#Dataset\n",
    "from torch.utils.data import Dataset\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import sys\n",
    "import os\n",
    "# from gensim.corpora import WikiCorpus\n",
    "import glob\n",
    "# import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f9616-2e7f-4939-8e21-c25be905499f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import pre-trained glove\n",
    "# words = []\n",
    "# idx = 0\n",
    "# word2idx = {}\n",
    "\n",
    "# vectors = bcolz.carray(np.zeros(1), rootdir=f'D:\\Jupyter\\Glove6B/6B.{dimension}.dat', mode = \"w\")\n",
    "\n",
    "# with open(f'D:\\Jupyter\\Glove6B/glove.6B.{dimension}d.txt', 'rb') as f:\n",
    "#     for l in f:\n",
    "#         line = l.decode().split()\n",
    "#         word = line[0]\n",
    "#         words.append(word)\n",
    "#         word2idx[word] = idx\n",
    "#         idx += 1\n",
    "#         vect = np.array(line[1:]).astype(float)\n",
    "#         vectors.append(vect)\n",
    "\n",
    "# vectors = bcolz.carray(vectors[1:].reshape((-1, 50)), rootdir=f'D:\\Jupyter\\Glove6B/6B.{dimension}.dat', mode = \"w\")\n",
    "# vectors.flush()\n",
    "\n",
    "# pickle.dump(words, open(f'D:\\Jupyter\\Glove6B/6B.{dimension}_words.pk1', 'wb'))\n",
    "# pickle.dump(word2idx, open(f'D:\\Jupyter\\Glove6B/6B.{dimension}_idx.pk1', 'wb'))\n",
    "\n",
    "# vectors = bcolz.open(f'D:\\Jupyter\\Glove6B/6B.{dimension}.dat')[:]\n",
    "# words = pickle.load(open(f'D:\\Jupyter\\Glove6B/6B.{dimension}_words.pk1', 'rb'))\n",
    "# word2idx = pickle.load(open(f'D:\\Jupyter\\Glove6B/6B.{dimension}_idx.pk1', 'rb'))\n",
    "\n",
    "# glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b5d69c-1bb7-4fae-9b20-92285b9ad900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "# And dig deep trenches in thy beauty's field,\n",
    "# Thy youth's proud livery so gazed on now,\n",
    "# Will be a totter'd weed of small worth held:\n",
    "# Then being asked, where all thy beauty lies,\n",
    "# Where all the treasure of thy lusty days;\n",
    "# To say, within thine own deep sunken eyes,\n",
    "# Were an all-eating shame, and thriftless praise.\n",
    "# How much more praise deserv'd thy beauty's use,\n",
    "# If thou couldst answer 'This fair child of mine\n",
    "# Shall sum my count, and make my old excuse,'\n",
    "# Proving his beauty by succession thine!\n",
    "# This were to be new made when thou art old,\n",
    "# And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "\n",
    "# EMBEDDING_DIM = dimension\n",
    "\n",
    "# vocab = set(train_sentence)\n",
    "# vocab_size = len(vocab)\n",
    "# weights_matrix = np.zeros((vocab_size, dimension))\n",
    "# words_found = 0\n",
    "\n",
    "# for i, word in enumerate(vocab):\n",
    "#     try: \n",
    "#         weights_matrix[i] = glove[word]\n",
    "#         words_found += 1\n",
    "#     except KeyError:\n",
    "#         weights_matrix[i] = np.random.normal(scale=0.6, size = (EMBEDDING_DIM, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4735c31-d552-4677-8b85-40d192f889fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def create_emb_layer(weights_matrix, non_trainable = False):\n",
    "#     num_embeddings, embedding_dim = weights_matrix.size()\n",
    "#     emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "#     emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "#     if non_trainable:\n",
    "#         emb_layer.weight.requires_grad = False\n",
    "    \n",
    "#     return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "# class ToyNN(nn.Module):\n",
    "#     def __init__(self, weights_matrix, hidden_size, num_layers):\n",
    "#         super(self).__init__()\n",
    "#         self.embedding, num_embeddings, embedding_dim = create_emb_labyer(weights_matrix, True)\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.gru = nn.GRU(embedding_dim, hidden_size, num_layers, batch_first = True)\n",
    "        \n",
    "#     def forward(self, inp, hidden):\n",
    "#         return self.gru(self.embedding(inp), hidden)\n",
    "    \n",
    "#     def init_hidden(self, batch_size):\n",
    "#         return Variable(torch.zeros(self.num_layers, batch_size, self.heiidn_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310e095a-125a-4890-9c8f-e49d49a4da77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fnv1a(txt):\n",
    "    # 64 bit fnv-1a\n",
    "    txt = bytes(txt, 'utf-8')\n",
    "    hval = 0xcbf29ce484222325\n",
    "    fnv_prime = 0x100000001b3\n",
    "    for c in txt:\n",
    "        hval = hval ^ c\n",
    "        hval = (hval * fnv_prime) % K\n",
    "    return hval        \n",
    "\n",
    "def subword_hashes(word):\n",
    "    sub_hash = []\n",
    "    tword = '<' + word + '>'\n",
    "    sub_hash.append(fnv1a(tword))\n",
    "    for n in range(3,7):\n",
    "        for i in range(len(tword)-n+1):\n",
    "            sub_hash.append(fnv1a(tword[i:i+n]))\n",
    "    return sub_hash\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e445ff-bd6e-4b00-9b5f-097b839783e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class fasttext_dataset(Dataset):\n",
    "    def __init__(self, in_f, SOURCE, CONTEXT_SIZE, SUBSAMPLING, REJ_THRESHOLD, MIN_FREQ, FORMAT, limit = None):\n",
    "        vocab, text_dict = self.make_dict(in_f, SOURCE, SUBSAMPLING, REJ_THRESHOLD, MIN_FREQ, FORMAT, limit)\n",
    "        training_data = self.get_training_data(text_dict, CONTEXT_SIZE)\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.text_dict = text_dict\n",
    "        \n",
    "        self.data = torch.tensor(training_data, dtype = torch.long)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        target = self.data[idx, 0]\n",
    "        context = self.data[idx, 1]\n",
    "        return target, context\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def make_dict(self, in_f, source, subsampling, rej_threshold, min_freq, FORMAT, limit):\n",
    "        print(\"Gathering texts....\")\n",
    "        body_tag = FORMAT[source]\n",
    "        t_dict = {}\n",
    "        text_list = [None]\n",
    "        for path in tqdm(glob.glob(in_f)):\n",
    "            if limit is not None:\n",
    "                limit -= 1\n",
    "                if limit < 0:\n",
    "                    break\n",
    "            f = open(path, errors = 'ignore')\n",
    "            data = f.read()\n",
    "            file_type = path[len(path) -3:]\n",
    "            if file_type == 'xml':\n",
    "                root = BeautifulSoup(data, 'xml')\n",
    "                paragraphs = root.find_all(body_tag)\n",
    "            elif file_type == 'txt':\n",
    "                paragraphs = [data]\n",
    "            else:\n",
    "                paragraphs = [data]\n",
    "                \n",
    "            for x in paragraphs:\n",
    "                text = x.text.lower()\n",
    "                words = word_tokenize(text)\n",
    "                for w in words:\n",
    "                    text_list.append(w)\n",
    "                text_list.append(None)\n",
    "            f.close()\n",
    "            \n",
    "#         print(\"Lemmatizing and removing stopwords...\")\n",
    "#         lem_text_list = []\n",
    "#         lem = WordNetLemmatizer()\n",
    "#         stop_words = set(stopwords.words('english'))\n",
    "#         stop_words = set()\n",
    "#         for w in tqdm(text_list):\n",
    "#             if w is None:\n",
    "#                 lem_text_list.append(w)\n",
    "#                 continue\n",
    "#             w = lem.lemmatize(w, 'v')\n",
    "#             if w not in stop_words:\n",
    "#             lem_text_list.append(w)\n",
    "        voc, text_list = self.get_word_freqs(text_list, subsampling, rej_threshold, min_freq)\n",
    "#         print(\"\\n\\n\\n\", vocab)\n",
    "        print(\"Constructing Dictionary...\")\n",
    "        for idx, w in tqdm(enumerate(text_list)):\n",
    "            t_dict[idx] = w\n",
    "#         print(text_dict)\n",
    "        print(\"Dictionary creation completed.\")\n",
    "        return voc, t_dict\n",
    "    \n",
    "    def get_training_data(self, text_dict, context_size):\n",
    "        training_data = []\n",
    "        for t_idx in range(len(text_dict)):\n",
    "            if text_dict[t_idx] is None:\n",
    "                continue\n",
    "            for sign in [-1,1]:\n",
    "                for w in range(1, context_size+1):\n",
    "                    c_idx = t_idx + w*sign\n",
    "                    if text_dict[c_idx] is None:\n",
    "                        break\n",
    "                    training_data.append([t_idx, c_idx])\n",
    "        return training_data\n",
    "    \n",
    "    def get_word_freqs(self, text_list, subsampling, rej_threshold, min_freq):\n",
    "        v = {}\n",
    "        total = 0.0\n",
    "        new_text_list = []\n",
    "        for word in text_list:\n",
    "            if word is not None:\n",
    "                if word not in v:\n",
    "                    v[word] = 0.0\n",
    "                v[word] += 1.0\n",
    "                total += 1.0\n",
    "#         print(\"\\nSubsampling: \", subsampling)\n",
    "# #         a = 100\n",
    "# #         print(len(text_list))\n",
    "#         if subsampling:\n",
    "#             print(\"Subsampling...\")\n",
    "#             for w in tqdm(text_list):\n",
    "# #                 print(word)\n",
    "#                 word = w\n",
    "#                 if word is not None:\n",
    "#                     fq = v[word]/total\n",
    "#                     prob = 1 - np.sqrt(rej_threshold/fq)\n",
    "#                     sampling = np.random.sample()\n",
    "#                     print(word, prob, sampling)\n",
    "#                     if sampling < prob or v[word] < min_freq:\n",
    "#                         text_list.remove(word)\n",
    "#             print(len(text_list))\n",
    "        return v, text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3f7e2d-49e6-45e0-8d15-c9896d2e13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_folder = \"D:/VISTEC Intern/corpus/blogs/*\"\n",
    "SOURCE = 'blog'\n",
    "CONTEXT_SIZE = 3\n",
    "SUBSAMPLING = True\n",
    "REJ_THRESHOLD = 1e-5\n",
    "MIN_FREQ = 2\n",
    "FORMAT = {'blog':'post'}\n",
    "\n",
    "# total embeddings\n",
    "K = int(2e6)\n",
    "\n",
    "dimension = 50\n",
    "neg_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd21bf94-c319-4b7a-8a4d-13273e38a8cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/19320 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 10/19320 [00:01<56:09,  5.73it/s]\n",
      "229307it [00:00, 2669810.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Dictionary...\n",
      "Dictionary creation completed.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = fasttext_dataset(in_folder, SOURCE, CONTEXT_SIZE, SUBSAMPLING, REJ_THRESHOLD, \n",
    "                                 MIN_FREQ, FORMAT, limit = 10)\n",
    "# print(train_dataset.text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a30ffa4-606a-47ce-8414-fcd1d632eddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FastText_Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, subword_size, embedding_dim, noise_dist, neg_samples, text_dict, vocab, debug = False):\n",
    "        super().__init__()\n",
    "        self.subword_embedding = nn.Embedding(subword_size, embedding_dim)\n",
    "        self.neg_samples = neg_samples\n",
    "        self.dimension = embedding_dim\n",
    "        self.embedding_size = subword_size\n",
    "        self.noise_dist = noise_dist\n",
    "        self.text_dict = text_dict\n",
    "        self.vocab = vocab\n",
    "        self.debug = debug\n",
    "        self.subword_embedding.weight.data.uniform_(-0.05,0.05)\n",
    "    \n",
    "    def forward(self, target_idx, context_idx):\n",
    "        debug = self.debug\n",
    "#         print(target_idx.shape, context_idx.shape)\n",
    "        first = True\n",
    "        for idx in target_idx.tolist():\n",
    "            target = self.text_dict[idx]\n",
    "#             print(target)\n",
    "            t_hash = torch.tensor(subword_hashes(target), dtype = torch.long)\n",
    "#             print(t_hash)\n",
    "#             print('t_hash.shape: ', t_hash.shape)\n",
    "#             print(self.subword_embedding(t_hash))\n",
    "            t_vec = torch.sum(self.subword_embedding(t_hash), dim = 0)\n",
    "#             print('t_vec.shape: ', t_vec.shape)\n",
    "            if first:\n",
    "                batch_t_vec = t_vec.detach().clone()\n",
    "                first = False\n",
    "            else:\n",
    "                batch_t_vec = torch.cat((batch_t_vec,t_vec), dim = 0)\n",
    "#         print(self.dimension)\n",
    "        batch_t_vec = batch_t_vec.view(target_idx.shape[0], self.dimension)\n",
    "        if debug:print(\"batch_t_vec.shape: \", batch_t_vec.shape)\n",
    "        \n",
    "        first = True\n",
    "        for idx in context_idx.tolist():\n",
    "            context = self.text_dict[idx]\n",
    "            c_hash = torch.tensor(subword_hashes(context), dtype = torch.long)\n",
    "#             print('c_hash.shape: ', c_hash.shape)\n",
    "            c_vec = torch.sum(self.subword_embedding(c_hash), dim = 0)\n",
    "#             print('c_vec.shape: ', c_vec.shape)\n",
    "            if first:\n",
    "                batch_c_vec = c_vec.detach().clone()\n",
    "                first = False\n",
    "            else:\n",
    "                batch_c_vec = torch.cat((batch_c_vec,c_vec), dim = 0)\n",
    "        batch_c_vec = batch_c_vec.view(context_idx.shape[0], self.dimension)\n",
    "        if debug:print(\"batch_c_vec.shape: \", batch_c_vec.shape)\n",
    "        \n",
    "        # negatives    \n",
    "# excluding context words from negative samples\n",
    "#         cts = set()\n",
    "#         for sign in [-1,1]:\n",
    "#             for w in range(1, CONTEXT_SIZE+1):\n",
    "#                 c_idx = target_idx + w*sign\n",
    "#                 if text_dict[c_idx] is None:\n",
    "#                     break\n",
    "#                 cts.add(text_dict[c_idx])\n",
    "#         W = {}\n",
    "#         P_vec = []\n",
    "#         for w in self.noise_dist:\n",
    "#             if w not in cts:\n",
    "#                 total += self.noise_dist[w]\n",
    "                \n",
    "#         for i,w in enumerate(self.noise_dist):\n",
    "#             if w not in cts:\n",
    "#                 fq = self.noise_dist[w]/total\n",
    "#                 prob = 1 - np.sqrt(REJ_THRESHOLD/fq)\n",
    "#                 W[i] = w\n",
    "#                 P_vec.append(prob)\n",
    "#         distr = torch.tensor(P_vec, dtype = torch.long)\n",
    "\n",
    "        distr = self.noise_dist\n",
    "        ngs = torch.multinomial(distr, context_idx.shape[0]*self.neg_samples, replacement = True)\n",
    "        if debug: print('negative_samples.shape', ngs.shape)\n",
    "            \n",
    "        ngs = ngs.view(context_idx.shape[0], self.neg_samples)\n",
    "        if debug: print('negative_samples.shape', ngs.shape)\n",
    "            \n",
    "#         print(noise_dist)\n",
    "        keys = list(self.vocab.keys())\n",
    "        first_neg = True\n",
    "        for neg_c in ngs.tolist():\n",
    "#             if debug: print(\"neg_c\", neg_c)\n",
    "            ns_words = [keys[i] for i in neg_c]\n",
    "            first = True\n",
    "            for word in ns_words:\n",
    "                nc_hash = torch.tensor(subword_hashes(word), dtype = torch.long)\n",
    "#                 if debug:print('n_c_hash.shape: ', nc_hash.shape)\n",
    "                nc_vec = torch.sum(self.subword_embedding(nc_hash), dim = 0)\n",
    "#                 if debug:print('n_c_vec.shape: ', nc_vec.shape)\n",
    "                if first:\n",
    "                    batch_nc_vec = nc_vec.detach().clone()\n",
    "                    first = False\n",
    "                else:\n",
    "                    batch_nc_vec = torch.cat((batch_nc_vec,nc_vec), dim = 0)\n",
    "            if first_neg:\n",
    "                batch_n_vec = batch_nc_vec.detach().clone()\n",
    "                first_neg = False\n",
    "            else:\n",
    "                batch_n_vec = torch.cat((batch_n_vec,batch_nc_vec), dim = 0)\n",
    "            \n",
    "#             print(\"batch_nc_vec.shape: \", batch_nc_vec.shape)\n",
    "        batch_n_vec = batch_n_vec.view(target_idx.shape[0], self.neg_samples, self.dimension)\n",
    "        if debug: print(\"batch_n_vec.shape: \", batch_n_vec.shape)\n",
    "        return batch_t_vec, batch_c_vec, batch_n_vec\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        print(f\"\\n###### BATCH {batch_idx} ######\")\n",
    "        debug = self.debug\n",
    "        \n",
    "        x, y = batch\n",
    "        if debug:\n",
    "            print(\"x.shape: \", x.shape)\n",
    "            print(\"y.shape: \", y.shape)\n",
    "        t_vec, c_vec, n_vec = self(x,y)\n",
    "        if debug:print(\"t_vec, c_vec, n_vec.shape\\n\", t_vec.shape, c_vec.shape, n_vec.shape)\n",
    "        \n",
    "        emb_product = torch.mul(t_vec, c_vec)\n",
    "        if debug:print(\"positive product.shape\", emb_product.shape)\n",
    "            \n",
    "        emb_product = torch.sum(emb_product, dim=1)\n",
    "        if debug:print(\"positive sum.shape\", emb_product.shape)\n",
    "            \n",
    "        pos_loss = F.logsigmoid(emb_product)\n",
    "        if debug:print(\"pos_loss.shape\", pos_loss.shape)\n",
    "            \n",
    "        # negative\n",
    "        if debug:print(\"\\nt_vec.unsqueeze(2).shape: \", t_vec.unsqueeze(2).shape)\n",
    "        neg_product = torch.bmm(n_vec.neg(), t_vec.unsqueeze(2))\n",
    "        if debug:print(\"nega_product.shape\", neg_product.shape)\n",
    "\n",
    "        neg_loss = F.logsigmoid(neg_product).squeeze(2).sum(1)\n",
    "        if debug:print(\"neg_loss.shape\", neg_shape.shape)\n",
    "\n",
    "        total_loss = -(pos_loss + neg_loss).mean()\n",
    "        if debug:print(\"total_loss.shape\", total_loss.shape)\n",
    "           \n",
    "        print(\"total_loss\", total_loss)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "457d1486-61b4-42c5-b4ab-4b71a6ae2486",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name              | Type      | Params\n",
      "------------------------------------------------\n",
      "0 | subword_embedding | Embedding | 100 M \n",
      "------------------------------------------------\n",
      "100 M     Trainable params\n",
      "0         Non-trainable params\n",
      "100 M     Total params\n",
      "400.000   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e7f76171b045b2a37b88d6f2867394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### BATCH 0 ######\n",
      "total_loss tensor(4.1730, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 1 ######\n",
      "total_loss tensor(4.1737, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 2 ######\n",
      "total_loss tensor(4.0967, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 3 ######\n",
      "total_loss tensor(4.0943, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 4 ######\n",
      "total_loss tensor(4.0876, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 5 ######\n",
      "total_loss tensor(4.1068, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 6 ######\n",
      "total_loss tensor(4.2923, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 7 ######\n",
      "total_loss tensor(4.1979, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 8 ######\n",
      "total_loss tensor(4.4161, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 9 ######\n",
      "total_loss tensor(4.7129, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 10 ######\n",
      "total_loss tensor(4.5952, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 11 ######\n",
      "total_loss tensor(4.4375, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 12 ######\n",
      "total_loss tensor(4.4816, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 13 ######\n",
      "total_loss tensor(4.5731, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 14 ######\n",
      "total_loss tensor(4.7965, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 15 ######\n",
      "total_loss tensor(4.9461, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 16 ######\n",
      "total_loss tensor(5.3890, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 17 ######\n",
      "total_loss tensor(4.3848, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 18 ######\n",
      "total_loss tensor(4.0986, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 19 ######\n",
      "total_loss tensor(5.3344, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 20 ######\n",
      "total_loss tensor(4.6034, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 21 ######\n",
      "total_loss tensor(4.3663, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 22 ######\n",
      "total_loss tensor(3.9251, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 23 ######\n",
      "total_loss tensor(4.0917, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 24 ######\n",
      "total_loss tensor(4.4038, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 25 ######\n",
      "total_loss tensor(4.2754, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 26 ######\n",
      "total_loss tensor(4.6111, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 27 ######\n",
      "total_loss tensor(5.4802, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 28 ######\n",
      "total_loss tensor(6.7243, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 29 ######\n",
      "total_loss tensor(5.5405, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 30 ######\n",
      "total_loss tensor(9.5631, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 31 ######\n",
      "total_loss tensor(5.4264, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 32 ######\n",
      "total_loss tensor(5.3625, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 33 ######\n",
      "total_loss tensor(5.5628, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 34 ######\n",
      "total_loss tensor(5.5273, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 35 ######\n",
      "total_loss tensor(5.2559, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 36 ######\n",
      "total_loss tensor(4.4914, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 37 ######\n",
      "total_loss tensor(6.0650, grad_fn=<NegBackward>)\n",
      "\n",
      "###### BATCH 38 ######\n",
      "total_loss tensor(4.3611, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 20)\n",
    "\n",
    "word_freqs = np.array(list(train_dataset.vocab.values()))\n",
    "unigram_dist = word_freqs/sum(word_freqs)\n",
    "noise_dist = torch.from_numpy(unigram_dist**(0.75)/np.sum(unigram_dist**(0.75)))\n",
    "\n",
    "trainer = pl.Trainer()\n",
    "model = FastText_Model(K, dimension, noise_dist, neg_samples, train_dataset.text_dict, train_dataset.vocab, False)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54f873-1fc8-465b-8033-0df080c6ba1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fq = np.array([1,2,3])\n",
    "ud = fq/sum(fq)\n",
    "nd = torch.from_numpy(ud/np.sum(ud))\n",
    "xd = np.array([1]*5)\n",
    "print(np.sqrt(1/xd))\n",
    "print(1-xd)\n",
    "print(np.array([1,2,3]) - np.array([1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4fd512-d387-400b-ba33-22e62a6833bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = torch.tensor([[1,2,3],[4,5,6]], dtype = torch.long)\n",
    "g = torch.tensor([[7,8,9],[10,11,12]], dtype = torch.long)\n",
    "print(torch.sum(f,dim=0))\n",
    "h = torch.cat((f,g))\n",
    "print(h.shape)\n",
    "h = h.view(2,2,3)\n",
    "print(h.shape)\n",
    "print(h.unsqueeze(2))\n",
    "    \n",
    "# e = f.detach().clone()\n",
    "# e = torch.cat((e,f),dim=0)\n",
    "# print(e)\n",
    "# print(f)\n",
    "\n",
    "# print(torch.cat((e,f), dim = 0))\n",
    "# print(f.shape)\n",
    "# print(torch.sum(f, dim=0))\n",
    "# print(torch.cat((f,f), dim =0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2869445b-dce8-4992-b9be-1f8acabc2821",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class test(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(20, 5)\n",
    "        self.embed.weight.data.uniform_(-0.05,0.05)\n",
    "        \n",
    "    def forward(self):\n",
    "        idx = torch.tensor([0,1], dtype = torch.long)\n",
    "        multiplier = self.embed(idx)\n",
    "        target = torch.tensor([[i for i in range(5)]], dtype = torch.long)\n",
    "        print(\"idx.shape: \", idx.shape)\n",
    "        print(\"idx: \", idx)\n",
    "        print(\"\\nmultiplier.shape: \", multiplier.shape)\n",
    "        print(\"multiplier: \", multiplier)\n",
    "        print(\"\\ntarget.shape: \", target.shape)\n",
    "        print(\"target: \", target)\n",
    "        \n",
    "        product = torch.mul(target, multiplier)\n",
    "        print(\"\\nproduct.shape: \", product.shape)\n",
    "        print(\"product: \", product)\n",
    "        emb_sum = torch.sum(product, dim=1)\n",
    "        print(\"\\nsum.shape: \", emb_sum.shape)\n",
    "        print(\"sum: \", emb_sum)\n",
    "        \n",
    "        noise_dist = torch.ones(20)\n",
    "        ng = torch.multinomial(noise_dist,5, replacement = True)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6fb4e-b1c0-4b6e-a595-ec6ef6d51bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tt = test()\n",
    "# optimizer = optim.Adam(tt.parameteres(), lr = 0.001)\n",
    "tt.train()\n",
    "# optimizer.zerp_grad()\n",
    "loss = tt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6779973c-c80d-480b-92dd-a0f9207a0400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "a = {'b':2,'a':1}\n",
    "print(list(a.keys())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ed9364-2e62-4e04-9413-9c4099932acf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3]\n",
    "print(torch.tensor([x], dtype = torch.long).shape)\n",
    "print(torch.tensor([i for i in x], dtype = torch.long).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a683586e-61bd-454f-87a1-efa7cdfde4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "a = {'a':1, 'b':2, 'c':20}\n",
    "b = [word for word in a]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4459ba21-d053-4bed-a7f6-6d98504223d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "a = {1,2,3}\n",
    "a.add(1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc129fd8-e054-46fb-924c-9f74cc2673ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,0,0,0],[2,0,0,0],[3,0,0,0],[4,0,0,0]])\n",
    "v = torch.tensor([[0,0,0,1],[0,0,0,2],[0,0,0,3],[0,0,0,4]])\n",
    "xc = torch.tensor([[1,2,1,1]])\n",
    "sv = torch.tensor([[1,0,0,0],[1,2,0,0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa87c53-902d-4685-a841-bb6d50c2645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x189578b1750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import bcolz\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "#Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f9616-2e7f-4939-8e21-c25be905499f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import pre-trained glove\n",
    "# words = []\n",
    "# idx = 0\n",
    "# word2idx = {}\n",
    "\n",
    "# vectors = bcolz.carray(np.zeros(1), rootdir=f'D:\\Jupyter\\Glove6B/6B.{dimension}.dat', mode = \"w\")\n",
    "\n",
    "# with open(f'D:\\Jupyter\\Glove6B/glove.6B.{dimension}d.txt', 'rb') as f:\n",
    "#     for l in f:\n",
    "#         line = l.decode().split()\n",
    "#         word = line[0]\n",
    "#         words.append(word)\n",
    "#         word2idx[word] = idx\n",
    "#         idx += 1\n",
    "#         vect = np.array(line[1:]).astype(float)\n",
    "#         vectors.append(vect)\n",
    "\n",
    "# vectors = bcolz.carray(vectors[1:].reshape((-1, 50)), rootdir=f'D:\\Jupyter\\Glove6B/6B.{dimension}.dat', mode = \"w\")\n",
    "# vectors.flush()\n",
    "\n",
    "# pickle.dump(words, open(f'D:\\Jupyter\\Glove6B/6B.{dimension}_words.pk1', 'wb'))\n",
    "# pickle.dump(word2idx, open(f'D:\\Jupyter\\Glove6B/6B.{dimension}_idx.pk1', 'wb'))\n",
    "\n",
    "# vectors = bcolz.open(f'D:\\Jupyter\\Glove6B/6B.{dimension}.dat')[:]\n",
    "# words = pickle.load(open(f'D:\\Jupyter\\Glove6B/6B.{dimension}_words.pk1', 'rb'))\n",
    "# word2idx = pickle.load(open(f'D:\\Jupyter\\Glove6B/6B.{dimension}_idx.pk1', 'rb'))\n",
    "\n",
    "# glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b5d69c-1bb7-4fae-9b20-92285b9ad900",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "# And dig deep trenches in thy beauty's field,\n",
    "# Thy youth's proud livery so gazed on now,\n",
    "# Will be a totter'd weed of small worth held:\n",
    "# Then being asked, where all thy beauty lies,\n",
    "# Where all the treasure of thy lusty days;\n",
    "# To say, within thine own deep sunken eyes,\n",
    "# Were an all-eating shame, and thriftless praise.\n",
    "# How much more praise deserv'd thy beauty's use,\n",
    "# If thou couldst answer 'This fair child of mine\n",
    "# Shall sum my count, and make my old excuse,'\n",
    "# Proving his beauty by succession thine!\n",
    "# This were to be new made when thou art old,\n",
    "# And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "\n",
    "# EMBEDDING_DIM = dimension\n",
    "\n",
    "# vocab = set(train_sentence)\n",
    "# vocab_size = len(vocab)\n",
    "# weights_matrix = np.zeros((vocab_size, dimension))\n",
    "# words_found = 0\n",
    "\n",
    "# for i, word in enumerate(vocab):\n",
    "#     try: \n",
    "#         weights_matrix[i] = glove[word]\n",
    "#         words_found += 1\n",
    "#     except KeyError:\n",
    "#         weights_matrix[i] = np.random.normal(scale=0.6, size = (EMBEDDING_DIM, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4735c31-d552-4677-8b85-40d192f889fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def create_emb_layer(weights_matrix, non_trainable = False):\n",
    "#     num_embeddings, embedding_dim = weights_matrix.size()\n",
    "#     emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "#     emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "#     if non_trainable:\n",
    "#         emb_layer.weight.requires_grad = False\n",
    "    \n",
    "#     return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "# class ToyNN(nn.Module):\n",
    "#     def __init__(self, weights_matrix, hidden_size, num_layers):\n",
    "#         super(self).__init__()\n",
    "#         self.embedding, num_embeddings, embedding_dim = create_emb_labyer(weights_matrix, True)\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.gru = nn.GRU(embedding_dim, hidden_size, num_layers, batch_first = True)\n",
    "        \n",
    "#     def forward(self, inp, hidden):\n",
    "#         return self.gru(self.embedding(inp), hidden)\n",
    "    \n",
    "#     def init_hidden(self, batch_size):\n",
    "#         return Variable(torch.zeros(self.num_layers, batch_size, self.heiidn_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310e095a-125a-4890-9c8f-e49d49a4da77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fnv1a(txt):\n",
    "    # 64 bit fnv-1a\n",
    "    txt = bytes(txt, 'utf-8')\n",
    "    hval = 0xcbf29ce484222325\n",
    "    fnv_prime = 0x100000001b3\n",
    "    for c in txt:\n",
    "        hval = hval ^ c\n",
    "        hval = (hval * fnv_prime) % K\n",
    "    return hval        \n",
    "\n",
    "def subword_hashes(word):\n",
    "    sub_hash = []\n",
    "    tword = '<' + word + '>'\n",
    "    sub_hash.append(fnv1a(tword))\n",
    "    for n in range(3,7):\n",
    "        for i in range(len(tword)-n+1):\n",
    "            sub_hash.append(fnv1a(tword[i:i+n]))\n",
    "    return sub_hash\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caab9a50-1139-4759-a7db-a326d25c0052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import sys\n",
    "import os\n",
    "# from gensim.corpora import WikiCorpus\n",
    "import glob\n",
    "# import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f484f2a-1f75-432b-a638-2a8717ad6516",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def make_corpus(in_f, out_f):\n",
    "#     output = open(out_f, 'w')\n",
    "#     wiki = WikiCorpus(in_f)\n",
    "#     i = 0\n",
    "#     for text in wiki.get_texts():\n",
    "#         output.write(bytes(' '.join(text), 'utf-8').decode('utf-8') + '\\n')\n",
    "#         i += 1\n",
    "#         if (i % 1e4 == 0):\n",
    "#             print('Processed ' + str(i) + ' articles')\n",
    "#     output.close()\n",
    "#     print('Processing Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e445ff-bd6e-4b00-9b5f-097b839783e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class fasttext_dataset(Dataset):\n",
    "    def __init__(self, in_f, SOURCE, CONTEXT_SIZE, SUBSAMPLING, REJ_THRESHOLD, MIN_FREQ, FORMAT, limit = None):\n",
    "        vocab, text_dict = self.make_dict(in_f, SOURCE, SUBSAMPLING, REJ_THRESHOLD, MIN_FREQ, FORMAT, limit)\n",
    "        training_data = self.get_training_data(text_dict, CONTEXT_SIZE)\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.text_dict = text_dict\n",
    "        \n",
    "        self.data = torch.tensor(training_data, dtype = torch.long)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        target = self.data[idx, 0]\n",
    "        context = self.data[idx, 1]\n",
    "        return target, context\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def make_dict(self, in_f, source, subsampling, rej_threshold, min_freq, FORMAT, limit):\n",
    "        print(\"Gathering texts....\")\n",
    "        body_tag = FORMAT[source]\n",
    "        t_dict = {}\n",
    "        text_list = [None]\n",
    "        for path in tqdm(glob.glob(in_f)):\n",
    "            if limit is not None:\n",
    "                limit -= 1\n",
    "                if limit < 0:\n",
    "                    break\n",
    "            f = open(path, errors = 'ignore')\n",
    "            data = f.read()\n",
    "            file_type = path[len(path) -3:]\n",
    "            if file_type == 'xml':\n",
    "                root = BeautifulSoup(data, 'xml')\n",
    "                paragraphs = root.find_all(body_tag)\n",
    "            elif file_type == 'txt':\n",
    "                paragraphs = [data]\n",
    "            else:\n",
    "                paragraphs = [data]\n",
    "                \n",
    "            for x in paragraphs:\n",
    "                text = x.text.lower()\n",
    "                words = word_tokenize(text)\n",
    "                for w in words:\n",
    "                    text_list.append(w)\n",
    "                text_list.append(None)\n",
    "            f.close()\n",
    "            \n",
    "#         print(\"Lemmatizing and removing stopwords...\")\n",
    "#         lem_text_list = []\n",
    "#         lem = WordNetLemmatizer()\n",
    "#         stop_words = set(stopwords.words('english'))\n",
    "#         stop_words = set()\n",
    "        for w in tqdm(text_list):\n",
    "            if w is None:\n",
    "                lem_text_list.append(w)\n",
    "                continue\n",
    "            w = lem.lemmatize(w, 'v')\n",
    "#             if w not in stop_words:\n",
    "            lem_text_list.append(w)\n",
    "        voc, text_list = self.get_word_freqs(lem_text_list, subsampling, rej_threshold, min_freq)\n",
    "#         print(\"\\n\\n\\n\", vocab)\n",
    "        print(\"Constructing Dictionary...\")\n",
    "        for idx, w in tqdm(enumerate(text_list)):\n",
    "            t_dict[idx] = w\n",
    "#         print(text_dict)\n",
    "        print(\"Dictionary creation completed.\")\n",
    "        return voc, t_dict\n",
    "    \n",
    "    def get_training_data(self, text_dict, context_size):\n",
    "        training_data = []\n",
    "        for t_idx in range(len(text_dict)):\n",
    "            if text_dict[t_idx] is None:\n",
    "                continue\n",
    "            for sign in [-1,1]:\n",
    "                for w in range(1, context_size+1):\n",
    "                    c_idx = t_idx + w*sign\n",
    "                    if text_dict[c_idx] is None:\n",
    "                        break\n",
    "                    training_data.append([t_idx, c_idx])\n",
    "        return training_data\n",
    "    \n",
    "    def get_word_freqs(self, text_list, subsampling, rej_threshold, min_freq):\n",
    "        v = {}\n",
    "        total = 0.0\n",
    "        new_text_list = []\n",
    "        for word in text_list:\n",
    "            if word is not None:\n",
    "                if word not in v:\n",
    "                    v[word] = 0.0\n",
    "                v[word] += 1.0\n",
    "                total += 1.0\n",
    "#         print(\"\\nSubsampling: \", subsampling)\n",
    "# #         a = 100\n",
    "# #         print(len(text_list))\n",
    "#         if subsampling:\n",
    "#             print(\"Subsampling...\")\n",
    "#             for w in tqdm(text_list):\n",
    "# #                 print(word)\n",
    "#                 word = w\n",
    "#                 if word is not None:\n",
    "#                     fq = v[word]/total\n",
    "#                     prob = 1 - np.sqrt(rej_threshold/fq)\n",
    "#                     sampling = np.random.sample()\n",
    "#                     print(word, prob, sampling)\n",
    "#                     if sampling < prob or v[word] < min_freq:\n",
    "#                         text_list.remove(word)\n",
    "#             print(len(text_list))\n",
    "        return v, text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa3f7e2d-49e6-45e0-8d15-c9896d2e13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_folder = \"D:/VISTEC Intern/corpus/blogs/*\"\n",
    "SOURCE = 'blog'\n",
    "CONTEXT_SIZE = 3\n",
    "SUBSAMPLING = True\n",
    "REJ_THRESHOLD = 1e-5\n",
    "MIN_FREQ = 2\n",
    "FORMAT = {'blog':'post'}\n",
    "\n",
    "# total embeddings\n",
    "K = int(2e6)\n",
    "\n",
    "dimension = 50\n",
    "neg_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd21bf94-c319-4b7a-8a4d-13273e38a8cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/19320 [00:01<54:31,  5.90it/s] \n",
      "  0%|          | 0/229307 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing and removing stopwords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229307/229307 [00:02<00:00, 110453.48it/s]\n",
      "  2%|▏         | 2904/136456 [00:00<00:04, 29013.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subsampling:  True\n",
      "Subsampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 73446/136456 [00:14<00:12, 4980.68it/s] \n",
      "73446it [00:00, 2727476.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Dictionary...\n",
      "Dictionary creation completed.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = fasttext_dataset(in_folder, SOURCE, CONTEXT_SIZE, SUBSAMPLING, REJ_THRESHOLD, \n",
    "                                 MIN_FREQ, FORMAT, limit = 10)\n",
    "# print(train_dataset.text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a30ffa4-606a-47ce-8414-fcd1d632eddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FastText_Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, subword_size, embedding_dim, distribution):\n",
    "        super().__init__()\n",
    "        self.subword_embeddings = nn.Embedding(subword_size, embedding_dim)\n",
    "        self.embedding_size = subword_size\n",
    "        self.distribution = distribution\n",
    "        self.subword_embeddings.weight.data.uniform_(-0.05,0.05)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(target_idx, context_idx)\n",
    "        target = train_dataset.text_dict[target_idx]\n",
    "        t_hash = subword_hashes(target)\n",
    "        t_vec = torch.zeros_like(self.subword_embeddings(t_hash[0]))\n",
    "        for h in t_hash:\n",
    "            t_vec += self.subword_embeddings(h)\n",
    "            \n",
    "        context = train_dataset.text_dict[context_idx]\n",
    "        c_hash = subword_hashes(target)\n",
    "        c_vec = torch.zeros_like(t_vec)\n",
    "        for h in c_hash:\n",
    "            c_vec += self.subword_embeddings(h)\n",
    "        \n",
    "        # negatives    \n",
    "        cts = set()\n",
    "        for sign in [-1,1]:\n",
    "            for w in range(1, CONTEXT_SIZE+1):\n",
    "                c_idx = target_idx + w*sign\n",
    "                if text_dict[c_idx] is None:\n",
    "                    break\n",
    "                cts.add(text_dict[c_idx])\n",
    "        W = {}\n",
    "        P_vec = []\n",
    "        for w in self.distribution:\n",
    "            if w not in cts:\n",
    "                total += self.distribution[w]\n",
    "                \n",
    "        for i,w in enumerate(self.distribution):\n",
    "            if w not in cts:\n",
    "                fq = self.distribution[w]/total\n",
    "                prob = 1 - np.sqrt(REJ_THRESHOLD/fq)\n",
    "                W[i] = w\n",
    "                P_vec.append(prob)\n",
    "        distr = torch.tensor(P_vec, dtype = torch.double)\n",
    "        ngs = torch.multinomial(distr, neg_samples, replacement = True)\n",
    "        ns = [W([int(i)]) for i in ngs]\n",
    "        print(ns)\n",
    "        hashes = [subword_hashes(w) for w in ns]\n",
    "        ns_vec = []\n",
    "        for hsh in hashes:\n",
    "            vec = torch.zeros_like(t_vec)\n",
    "            for h in hsh:\n",
    "                vec += self.subword_embeddings(h)\n",
    "            ns_vec.append(vec)\n",
    "#         return t_vec, c_vec, ns_vec\n",
    "        return torch.nn.Softmax()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx)\n",
    "        debug = True\n",
    "    \n",
    "        emb_product = torch.mul(t_vec, c_vec)\n",
    "        if debug:print(\"positive product.shape\", emb_product.shape)\n",
    "            \n",
    "        emb_product = torch.sum(emb_product, dim=1)\n",
    "        if debug:print(\"positive sum.shape\", emb_product.shape)\n",
    "            \n",
    "        pos_loss = F.logsigmoid(emb_product)\n",
    "        if debug:print(\"pos_loss.shape\", pos_loss.shape)\n",
    "            \n",
    "        # negative\n",
    "        neg_sum = torch.zeros_like(emb_product)\n",
    "        for nv in ns_vec:\n",
    "            neg_product = torch.mul(t_vec, nv)\n",
    "            if debug:print(\"negative product.shape\", neg_product.shape)\n",
    "            \n",
    "            neg_product = torch.sum(neg_product, dim=1)\n",
    "            if debug:print(\"negative sum.shape\", neg_product.shape)\n",
    "            \n",
    "            neg_sum += neg_product\n",
    "            if debug:print(\"negative sum.shape\", neg_loss.shape)\n",
    "        \n",
    "        loss = 1\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f5e90e6-10fd-48df-bd0e-34f25a18fdc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 20)\n",
    "trainer = pl.Trainer()\n",
    "model = FastText_Model(K, dimension, trainloader.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e842a1e0-608f-466e-9951-d088176d1adc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[3, 4, 5],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,1,1]], dtype =  torch.long)\n",
    "b = torch.tensor([[3,4,5],[1,1,1]], dtype = torch.long)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(torch.mul(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45846c70-bbc9-4d3a-ab87-735649b2a911",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a492bcc1a593>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcontext_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mCgram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtemp_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcontext_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcontext_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "# N_gram\n",
    "context_size = 2\n",
    "Cgram = []\n",
    "for i in range(len(train_sentence)):\n",
    "    temp_context = []\n",
    "    for j in range(max(0,i - context_size+1), min(len(train_sentence),i + context_size)):\n",
    "#         print(train_sentence[j], \" \", train_sentence[i])\n",
    "        if(j != i):\n",
    "            temp_context.append(train_sentence[j])\n",
    "    Cgram.append((temp_context, train_sentence[i]))\n",
    "    \n",
    "print(Cgram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b12a1148-da1f-4a93-873b-f6297c815373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FastText_neg_sampling(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, subtext_size, embedding_dim, context_size, noise_dist = None, negative_samples = 10):\n",
    "        super(FastText_neg_sampling, self).__init__()\n",
    "#         self.embeddings_input = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embeddings_subtext = nn.Embedding(subtext_size, embedding_dim)\n",
    "        self.embeddings_context = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.negative_samples = negative_samples\n",
    "        self.noise_dist = noise_dist\n",
    "        \n",
    "#         self.embeddings_input.weight.data.uniform_(-1,1)\n",
    "        self.embeddings_context.weight.data.uniform_(-0.05,0.05)\n",
    "        self.embeddings_subtext.weight.data.uniform_(-0.05,0.05)\n",
    "        \n",
    "#         self.linear1 = nn.Linear(context_size*embedding_dim, 128)\n",
    "#         self.linear2 = nn.Linear(128, vocab_size)\n",
    "    \n",
    "    def forward(self, subtext, context_word):\n",
    "        debug = True\n",
    "        if debug:\n",
    "#             print('input_word.shape: ', input_word.shape)\n",
    "            print('context_word.shape: ', context_word.shape)\n",
    "            print('subtext_word.shape: ', subtext.shape)\n",
    "            \n",
    "#         emb_input = self.embeddings_input(input_word)\n",
    "#         if debug: print('emb_input.shape: ', emb_input.shape)\n",
    "        \n",
    "        emb_context = self.embeddings_context(context_word)  \n",
    "        if debug:print('emb_context.shape: ', emb_context.shape)\n",
    "        \n",
    "        emb_target = self.embeddings_subtext(subtext)\n",
    "        emb_target = torch.sum(emb_target, 0).view(1,-1)\n",
    "        if debug:print('emb_subtext.shape: ', emb_target.shape)\n",
    "        \n",
    "        emb_product = torch.mul(emb_target, emb_context)\n",
    "        if debug: print('emb_product.shape: ', emb_product.shape)\n",
    "        \n",
    "        emb_score = torch.sum(emb_product, dim=1)\n",
    "        if debug: print('emb_score.shape: ', emb_score.shape)\n",
    "\n",
    "        out_loss = F.logsigmoid(emb_score)   \n",
    "#         out_loss = math.log(1 - math.exp(-emb_product))\n",
    "        if debug:print('out_loss.shape: ', out_loss.shape)\n",
    "            \n",
    "################ NEGATIVE SAMPLING #####################\n",
    "\n",
    "        if self.noise_dist is None:\n",
    "            noise_dist = torch.ones(self.vocab_size)\n",
    "        else:\n",
    "            noise_dist = self.noise_dist\n",
    "\n",
    "        if debug: print('noise_dist.shape: ', noise_dist.shape)\n",
    "\n",
    "        batch_neg_samples_num = context_word.shape[0]*self.negative_samples\n",
    "        negative_example = torch.multinomial(noise_dist, batch_neg_samples_num, replacement = True)\n",
    "        if debug: print('negative_example.shape: ', negative_example.shape)\n",
    "\n",
    "        negative_example = negative_example.view(context_word.shape[0], self.negative_samples) # bs, num_neg_samples\n",
    "        if debug:print('negative_example.shape: ', negative_example.shape)\n",
    "\n",
    "        emb_negative = self.embeddings_context(negative_example) # bs, neg_samples, emb_dim\n",
    "        if debug:print('emb_negative.shape: ', emb_negative.shape)\n",
    "\n",
    "        if debug: print('emb_target.unsqueeze(2).shape: ', emb_target.unsqueeze(2).shape)\n",
    "        emb_product_neg_samples = torch.bmm(emb_negative.neg(), emb_target.unsqueeze(2))\n",
    "        if debug: print('emb_product_neg_samples.shape: ', emb_product_neg_samples.shape)\n",
    "\n",
    "        noise_loss = F.logsigmoid(emb_product_neg_samples).squeeze(2).sum(1)\n",
    "        if debug: print('noise_loss.shape: ', noise_loss.shape)\n",
    "\n",
    "        total_loss = -(out_loss + noise_loss).mean()\n",
    "        if debug: print('total_loss.shape', total_loss.shape)\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fccf438a-af7e-4da2-85da-0c1850d7845b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== EPOCH 1/5 ==========\n",
      "context_word.shape:  torch.Size([1])\n",
      "subtext_word.shape:  torch.Size([10])\n",
      "emb_context.shape:  torch.Size([1, 50])\n",
      "emb_subtext.shape:  torch.Size([1, 50])\n",
      "emb_product.shape:  torch.Size([1, 50])\n",
      "emb_score.shape:  torch.Size([1])\n",
      "out_loss.shape:  torch.Size([1])\n",
      "noise_dist.shape:  torch.Size([97])\n",
      "negative_example.shape:  torch.Size([5])\n",
      "negative_example.shape:  torch.Size([1, 5])\n",
      "emb_negative.shape:  torch.Size([1, 5, 50])\n",
      "emb_target.unsqueeze(2).shape:  torch.Size([1, 50, 1])\n",
      "emb_product_neg_samples.shape:  torch.Size([1, 5, 1])\n",
      "noise_loss.shape:  torch.Size([1])\n",
      "total_loss.shape torch.Size([])\n",
      "context_word.shape:  torch.Size([2])\n",
      "subtext_word.shape:  torch.Size([15])\n",
      "emb_context.shape:  torch.Size([2, 50])\n",
      "emb_subtext.shape:  torch.Size([1, 50])\n",
      "emb_product.shape:  torch.Size([2, 50])\n",
      "emb_score.shape:  torch.Size([2])\n",
      "out_loss.shape:  torch.Size([2])\n",
      "noise_dist.shape:  torch.Size([97])\n",
      "negative_example.shape:  torch.Size([10])\n",
      "negative_example.shape:  torch.Size([2, 5])\n",
      "emb_negative.shape:  torch.Size([2, 5, 50])\n",
      "emb_target.unsqueeze(2).shape:  torch.Size([1, 50, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-46ecbcb5e15d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0msubtext_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubtext_to_ix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mngram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtext_idxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_idxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-151-352d4ca5b2df>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, subtext, context_word)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'emb_target.unsqueeze(2).shape: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0memb_product_neg_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb_negative\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'emb_product_neg_samples.shape: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb_product_neg_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = dimension\n",
    "ngs = 5\n",
    "\n",
    "vocab = set(train_sentence)\n",
    "word_to_ix = {word: index for index,word in enumerate(vocab)}\n",
    "ix_to_word = {index: word for index,word in enumerate(vocab)}\n",
    "subtext_to_ix = {word: index for index,word in enumerate(subtext)}\n",
    "ix_to_subtext = {index: word for index,word in enumerate(subtext)}\n",
    "\n",
    "word_count = {}\n",
    "for i in vocab:\n",
    "    word_count[i] = train_sentence.count(i)\n",
    "# print(word_count)\n",
    "\n",
    "word_freq = np.array([word_count[word] for word in vocab])\n",
    "unigram_dist = word_freq/word_freq.sum()\n",
    "ws = 1 - np.sqrt(10e-4/unigram_dist)\n",
    "ws = np.clip(ws,0,1)\n",
    "noise_dist = torch.from_numpy(unigram_dist**(0.75)/np.sum(unigram_dist**(0.75)))\n",
    "\n",
    "losses = []\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader()\n",
    "model = FastText_neg_sampling(len(vocab), subtext_size,  EMBEDDING_DIM, context_size, noise_dist, ngs)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "\n",
    "EPOCH = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCH):\n",
    "    print(f'\\n========== EPOCH {epoch+1}/{EPOCH} ==========')\n",
    "    total_loss = 0\n",
    "    for context, target in Cgram:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype = torch.long)\n",
    "#         target_idx = torch.tensor([word_to_ix[target]], dtype = torch.long)\n",
    "        subtext_idxs = torch.tensor([subtext_to_ix[w] for w in ngram[target]], dtype = torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(subtext_idxs, context_idxs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a683586e-61bd-454f-87a1-efa7cdfde4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "a = {'a':1, 'b':2, 'c':20}\n",
    "b = [word for word in a]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4459ba21-d053-4bed-a7f6-6d98504223d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "a = {1,2,3}\n",
    "a.add(1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cc129fd8-e054-46fb-924c-9f74cc2673ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "tensor([[10,  0,  0,  0]])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([2, 4])\n",
      "tensor([[1, 0, 0, 0],\n",
      "        [1, 4, 0, 0]])\n",
      "torch.Size([2])\n",
      "tensor([1, 5])\n",
      "torch.Size([4, 4])\n",
      "tensor([[1, 0, 0, 1],\n",
      "        [2, 0, 0, 2],\n",
      "        [3, 0, 0, 3],\n",
      "        [4, 0, 0, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,0,0,0],[2,0,0,0],[3,0,0,0],[4,0,0,0]])\n",
    "v = torch.tensor([[0,0,0,1],[0,0,0,2],[0,0,0,3],[0,0,0,4]])\n",
    "xc = torch.tensor([[1,2,1,1]])\n",
    "sv = torch.tensor([[1,0,0,0],[1,2,0,0]])\n",
    "print(a.shape)\n",
    "print(torch.sum(a, 0).view(1,-1))\n",
    "print(xc.shape)\n",
    "sc = torch.mul(xc,sv)\n",
    "print(sc.shape, sc, sep ='\\n')\n",
    "s = torch.sum(sc, dim=1)\n",
    "print(s.shape, s, sep = '\\n')\n",
    "z = a + v\n",
    "print(z.shape)\n",
    "print(z)\n",
    "# print(torch.sum(z, dim =1))\n",
    "# print(a)\n",
    "# print(a.shape)\n",
    "# g = torch.mul(xc,a)\n",
    "# print(g)\n",
    "# print(g.shape)\n",
    "# print(torch.sum(a,0).view(1,-1))\n",
    "# if(0): print('q')\n",
    "# c = torch.tensor([[0,0,0,1] for i in range(7)])\n",
    "# b = torch.tensor([], dtype = torch.long)\n",
    "# print(torch.cat((-xc,-xc*(-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "48258fa0-e029-44db-bf36-52a248ec3ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def sc(a = 1):\n",
    "    print(a)\n",
    "    \n",
    "sc(a = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d6f9b58-7ecf-47d9-a883-b3ec24ab8ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216b18d3-e1e3-4529-9270-e8dea670323d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d60b06f2c205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb949e-d7c2-47b7-828c-d036b98ffc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
